{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA_Project_stacking classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r8lWM7KPV2b",
        "outputId": "dcbd516a-d6ad-4c6a-d12f-a62894fff258"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUqnsC66HAcM",
        "outputId": "d9390b28-e487-4d6a-cc79-614d473b606a"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 4.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqPbJuAsScaZ",
        "outputId": "a743e49b-4abd-48d5-b2a6-5e935057845d"
      },
      "source": [
        "!git clone https://github.com/AlirezaAlizadeh/api-doc-kn-identification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'api-doc-kn-identification'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Total 25 (delta 0), reused 0 (delta 0), pack-reused 25\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ1DtJMXSFvd",
        "outputId": "9d2840ed-7da6-4400-bfc2-f755942cc0d5"
      },
      "source": [
        "%cd api-doc-kn-identification\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/api-doc-kn-identification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OHskDmnxS61"
      },
      "source": [
        "# Ensemble Learning on Cado Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnubz7qiL0eJ"
      },
      "source": [
        "import scripts.dataset_utils as du\n",
        "from skmultilearn.adapt import MLkNN\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay, classification_report\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeDxv6cVMI8w"
      },
      "source": [
        "MAX_NB_WORDS =20000\n",
        "\n",
        "def tokenize_data(X):\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(X)       \n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8oPM41GMKhX"
      },
      "source": [
        "    import pandas as pd\n",
        "    \n",
        "    data_path = '/content/drive/MyDrive/cado_data/train.csv'\n",
        "    test_path = '/content/drive/MyDrive/cado_data/test.csv'\n",
        "    \n",
        "    data =  du.load_data(data_path)\n",
        "    test = du.load_data(test_path)\n",
        "    \n",
        "    text_index = 6\n",
        "    label_start_index = 7 \n",
        "    X = [d[text_index] for d in data]\n",
        "    labels = [d[label_start_index:label_start_index+12] for d in data ]\n",
        "    \n",
        "    \n",
        "    X_test = [d[text_index] for d in test]\n",
        "    labels_test = [d[label_start_index:label_start_index+12] for d in test]\n",
        "    \n",
        "        \n",
        "    \n",
        "    Y = np.array(labels, dtype='int')\n",
        "    y_test = np.array(labels_test, dtype='int')\n",
        "    #Y = np.array(binary_labels, dtype='int')\n",
        "    \n",
        "    test_index = len(X)\n",
        "    \n",
        "    X = X + X_test\n",
        "    Y = np.vstack([Y , y_test])\n",
        "    \n",
        "    tokenizer = tokenize_data(X)\n",
        "    word_index = tokenizer.word_index\n",
        "    \n",
        "    sequences = tokenizer.texts_to_sequences(X)    \n",
        "\n",
        "    X = pad_sequences(sequences, maxlen=700, \n",
        "                      padding=\"post\", truncating=\"post\", value=0)   \n",
        "\n",
        "    num_words = min(MAX_NB_WORDS, len(word_index)+1)\n",
        "    embedding_matrix = np.zeros((num_words, 1))\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        if i >= MAX_NB_WORDS:\n",
        "            continue\n",
        "        embedding_matrix[i] = 1\n",
        "        \n",
        "    X_train = X[0:test_index , :]\n",
        "    Y_train = Y[0:test_index , :]\n",
        "    x_test = X[test_index:len(X), :]\n",
        "    y_test = Y[test_index:len(Y), :]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJjtF7-v5T5L",
        "outputId": "41e821f1-ec11-4020-eb2a-9151ef4b8118"
      },
      "source": [
        "type(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKrCyO9XDDmk"
      },
      "source": [
        "**Stacking Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iiIBHm6cTaCf",
        "outputId": "e1fd58c4-446d-44d1-c813-edcc7a357955"
      },
      "source": [
        "# Stacking classifier with one vs Rest wrapper and MLKnn - Model 1\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "estimators_list = [('ExtraTrees', ExtraTreesClassifier(n_estimators=30, \n",
        "                                                       class_weight=\"balanced\", \n",
        "                                                       random_state=4621)),\n",
        "                   ('linearSVC', SVC(class_weight=\"balanced\", probability=True))]\n",
        "\n",
        "estimators_ensemble = StackingClassifier(estimators=estimators_list,\n",
        "                                         final_estimator = LogisticRegression(max_iter=300))\n",
        "\n",
        "ovr_model = OneVsRestClassifier(estimators_ensemble)\n",
        "\n",
        "ovr_model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=StackingClassifier(estimators=[('ExtraTrees',\n",
              "                                                              ExtraTreesClassifier(class_weight='balanced',\n",
              "                                                                                   n_estimators=30,\n",
              "                                                                                   random_state=4621)),\n",
              "                                                             ('linearSVC',\n",
              "                                                              SVC(class_weight='balanced',\n",
              "                                                                  probability=True))],\n",
              "                                                 final_estimator=LogisticRegression(max_iter=300)))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2oH4QAYcl4It",
        "outputId": "56ba527e-05c3-444b-984d-e03b91133fd2"
      },
      "source": [
        "predictions = ovr_model.predict(x_test)\n",
        "   \n",
        "my_metrics= metrics.classification_report(y_test, predictions)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.86       302\n",
            "           1       0.50      0.06      0.11        51\n",
            "           2       0.86      0.17      0.28        71\n",
            "           3       0.82      0.12      0.21        74\n",
            "           4       0.93      0.82      0.87        17\n",
            "           5       1.00      0.21      0.35        33\n",
            "           6       0.64      0.48      0.55       160\n",
            "           7       0.55      0.25      0.34        69\n",
            "           8       0.68      0.40      0.50        91\n",
            "           9       0.93      0.82      0.87        17\n",
            "          10       0.78      0.14      0.24        50\n",
            "          11       0.60      0.29      0.39       127\n",
            "\n",
            "   micro avg       0.73      0.49      0.59      1062\n",
            "   macro avg       0.75      0.39      0.46      1062\n",
            "weighted avg       0.72      0.49      0.53      1062\n",
            " samples avg       0.67      0.42      0.49      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrrEmqArzlKf",
        "outputId": "89efd24b-4033-4c42-97cf-4c8f6dd73f89"
      },
      "source": [
        "metrics.hamming_loss(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1490695792880259"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCcbbR_5z3jY",
        "outputId": "e26eaab5-0bbf-44a3-8b63-63f007cced18"
      },
      "source": [
        "metrics.accuracy_score(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14320388349514562"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN5jwz82H03X",
        "outputId": "41bbc501-f3b0-4020-ee3f-0e0b47b06868"
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "print(predictions.shape)\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], predictions[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(412, 12)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{0: 0.7710175762641525,\n",
              " 1: 0.1459166190748144,\n",
              " 2: 0.28807309878689613,\n",
              " 3: 0.25727558979986165,\n",
              " 4: 0.7759090043784503,\n",
              " 5: 0.275228008237717,\n",
              " 6: 0.5051960647779723,\n",
              " 7: 0.2613234566556371,\n",
              " 8: 0.4096597397568271,\n",
              " 9: 0.7759090043784503,\n",
              " 10: 0.21325782092772383,\n",
              " 11: 0.38955021399024153}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzjC1nHFDHcR"
      },
      "source": [
        "**BinaryRelevance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JYRDjZTDVST",
        "outputId": "bc1b2214-37d5-45bf-8a44-dbc2016b91df"
      },
      "source": [
        "# binary relevance + RandomClassifier\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "start=time.time()\n",
        "classifier = BinaryRelevance(\n",
        "    classifier = RandomForestClassifier(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training time taken:  40.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2kW_PcTFSB1",
        "outputId": "d10e40a3-2c53-479b-9e1f-9c84c65a490b"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= metrics.classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.85       302\n",
            "           1       0.60      0.06      0.11        51\n",
            "           2       0.77      0.24      0.37        71\n",
            "           3       0.71      0.16      0.26        74\n",
            "           4       0.93      0.82      0.87        17\n",
            "           5       1.00      0.21      0.35        33\n",
            "           6       0.67      0.47      0.56       160\n",
            "           7       0.59      0.33      0.43        69\n",
            "           8       0.70      0.44      0.54        91\n",
            "           9       0.93      0.82      0.87        17\n",
            "          10       0.89      0.16      0.27        50\n",
            "          11       0.65      0.38      0.48       127\n",
            "\n",
            "   micro avg       0.74      0.51      0.60      1062\n",
            "   macro avg       0.77      0.42      0.50      1062\n",
            "weighted avg       0.73      0.51      0.56      1062\n",
            " samples avg       0.64      0.42      0.49      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaYSkbiaI1UX",
        "outputId": "89130ee2-b4f4-451b-ff99-8164a72eb8e9"
      },
      "source": [
        "metrics.hamming_loss(y_test,predictions1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14381067961165048"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLsskTwiS8Er",
        "outputId": "c8ddcc37-e3c5-4cd1-c70d-cd263a18567b"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.7758019344199525,\n",
              " 1: 0.15179897201599085,\n",
              " 2: 0.31608716731101527,\n",
              " 3: 0.26495284547825954,\n",
              " 4: 0.7759090043784503,\n",
              " 5: 0.275228008237717,\n",
              " 6: 0.5233525216943037,\n",
              " 7: 0.3082316820180898,\n",
              " 8: 0.43224987412519345,\n",
              " 9: 0.7759090043784503,\n",
              " 10: 0.24416396979503774,\n",
              " 11: 0.4369061171866768}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1Bo0DtxUr-t",
        "outputId": "63eabf6f-331f-42ac-d26b-a7d27b997904"
      },
      "source": [
        "# binary relevance + SVC\n",
        "start=time.time()\n",
        "classifier = BinaryRelevance(\n",
        "    classifier = RandomForestClassifier(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training time taken:  43.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiTZIyEhU65k",
        "outputId": "2214562d-b487-4b6c-b60a-233bb5390a12"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= metrics.classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84       302\n",
            "           1       0.60      0.06      0.11        51\n",
            "           2       0.74      0.20      0.31        71\n",
            "           3       0.77      0.14      0.23        74\n",
            "           4       0.93      0.82      0.87        17\n",
            "           5       1.00      0.21      0.35        33\n",
            "           6       0.68      0.48      0.56       160\n",
            "           7       0.53      0.26      0.35        69\n",
            "           8       0.72      0.48      0.58        91\n",
            "           9       0.93      0.82      0.87        17\n",
            "          10       0.89      0.16      0.27        50\n",
            "          11       0.65      0.39      0.49       127\n",
            "\n",
            "   micro avg       0.74      0.50      0.60      1062\n",
            "   macro avg       0.77      0.41      0.49      1062\n",
            "weighted avg       0.73      0.50      0.55      1062\n",
            " samples avg       0.65      0.42      0.49      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VbO1bsWVGk9",
        "outputId": "f9fad951-27cc-4a99-d38d-7f8365f24a49"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.7703710541751811,\n",
              " 1: 0.15179897201599085,\n",
              " 2: 0.2836423240516168,\n",
              " 3: 0.2592899097753467,\n",
              " 4: 0.7759090043784503,\n",
              " 5: 0.275228008237717,\n",
              " 6: 0.5293877266088152,\n",
              " 7: 0.2618938246467857,\n",
              " 8: 0.4628436580131631,\n",
              " 9: 0.7759090043784503,\n",
              " 10: 0.24416396979503774,\n",
              " 11: 0.44139387916316286}"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUTTWTNVK0A"
      },
      "source": [
        "**Label Powerset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLNFMNWZV6pm",
        "outputId": "1174780a-aa6e-4f27-edab-4a500f706bc1"
      },
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "\n",
        "classifier = LabelPowerset(\n",
        "    classifier = SVC(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "start=time.time()\n",
        "classifier.fit(X_train, Y_train)\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training time taken:  8.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wuxn0y8UWGeA",
        "outputId": "363e3ae9-d230-40d4-a020-1e4f3a920e9a"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= metrics.classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.98      0.85       302\n",
            "           1       1.00      0.02      0.04        51\n",
            "           2       1.00      0.10      0.18        71\n",
            "           3       0.80      0.05      0.10        74\n",
            "           4       1.00      0.41      0.58        17\n",
            "           5       1.00      0.12      0.22        33\n",
            "           6       0.52      0.57      0.55       160\n",
            "           7       1.00      0.09      0.16        69\n",
            "           8       1.00      0.07      0.12        91\n",
            "           9       0.83      0.29      0.43        17\n",
            "          10       1.00      0.04      0.08        50\n",
            "          11       0.38      0.64      0.47       127\n",
            "\n",
            "   micro avg       0.62      0.48      0.54      1062\n",
            "   macro avg       0.86      0.28      0.32      1062\n",
            "weighted avg       0.77      0.48      0.45      1062\n",
            " samples avg       0.57      0.44      0.48      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p7FwXjQYKUp",
        "outputId": "81729831-b631-482f-e2e4-ea444e706777"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.7502275728286223,\n",
              " 1: 0.14096706643822576,\n",
              " 2: 0.2539313551210174,\n",
              " 3: 0.21314615586460248,\n",
              " 4: 0.4360365505425471,\n",
              " 5: 0.19160047072668435,\n",
              " 6: 0.4656167255075022,\n",
              " 7: 0.23986914309835375,\n",
              " 8: 0.2722447455457164,\n",
              " 9: 0.2742242528079193,\n",
              " 10: 0.15650485436893205,\n",
              " 11: 0.35193614740356594}"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFkE2P68Yl5i"
      },
      "source": [
        "Research Question: can we find a classifier which can identify all the knowledge types in the best possible way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVuoprBYY92h"
      },
      "source": [
        "**ClassifierChain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxo4p3wzY9fa",
        "outputId": "15cf6de4-db14-4a1a-b520-788983739cdd"
      },
      "source": [
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "\n",
        "classifier = ClassifierChain(\n",
        "    classifier = RandomForestClassifier(),\n",
        "    require_dense = [False, True],\n",
        "    order=[i for i in range(12)]\n",
        ")\n",
        "start=time.time()\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassifierChain(classifier=RandomForestClassifier(),\n",
              "                order=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
              "                require_dense=[False, True])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwIvgMN3Y1e0",
        "outputId": "b9bd0b03-c4ef-4c86-983d-ddd71eaea22f"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= metrics.classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84       302\n",
            "           1       0.75      0.06      0.11        51\n",
            "           2       0.71      0.24      0.36        71\n",
            "           3       0.75      0.12      0.21        74\n",
            "           4       0.93      0.82      0.87        17\n",
            "           5       1.00      0.21      0.35        33\n",
            "           6       0.70      0.53      0.60       160\n",
            "           7       0.60      0.30      0.40        69\n",
            "           8       0.70      0.43      0.53        91\n",
            "           9       0.93      0.82      0.87        17\n",
            "          10       0.89      0.16      0.27        50\n",
            "          11       0.59      0.48      0.53       127\n",
            "\n",
            "   micro avg       0.73      0.52      0.61      1062\n",
            "   macro avg       0.78      0.43      0.50      1062\n",
            "weighted avg       0.73      0.52      0.56      1062\n",
            " samples avg       0.63      0.45      0.50      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVVyq5DYZ1vr",
        "outputId": "43cb44a4-87e0-43ac-a4b9-788254c615b9"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.771086089491463,\n",
              " 1: 0.16062250142775558,\n",
              " 2: 0.3006689001321847,\n",
              " 3: 0.24898320650747838,\n",
              " 4: 0.7759090043784503,\n",
              " 5: 0.275228008237717,\n",
              " 6: 0.5521720316727677,\n",
              " 7: 0.29911355002110596,\n",
              " 8: 0.4246829799881117,\n",
              " 9: 0.7759090043784503,\n",
              " 10: 0.24416396979503774,\n",
              " 11: 0.4446525494992737}"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhymb05BaF9e",
        "outputId": "408f0eba-646b-4bf1-dc1a-262392656047"
      },
      "source": [
        "classifier = ClassifierChain(\n",
        "    classifier = estimators_ensemble,\n",
        "    require_dense = [False, True],\n",
        "    order=[i for i in range(12)]\n",
        ")\n",
        "start=time.time()\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassifierChain(classifier=StackingClassifier(estimators=[('ExtraTrees',\n",
              "                                                           ExtraTreesClassifier(class_weight='balanced',\n",
              "                                                                                n_estimators=30,\n",
              "                                                                                random_state=4621)),\n",
              "                                                          ('linearSVC',\n",
              "                                                           SVC(class_weight='balanced',\n",
              "                                                               probability=True))],\n",
              "                                              final_estimator=LogisticRegression(max_iter=300)),\n",
              "                order=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
              "                require_dense=[False, True])"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FWW0-C3aVTN",
        "outputId": "512af0df-80eb-4216-8d69-e543d1c265d7"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= metrics.classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.94      0.85       302\n",
            "           1       0.50      0.06      0.11        51\n",
            "           2       0.82      0.20      0.32        71\n",
            "           3       0.75      0.12      0.21        74\n",
            "           4       0.93      0.82      0.87        17\n",
            "           5       1.00      0.21      0.35        33\n",
            "           6       0.60      0.53      0.56       160\n",
            "           7       0.56      0.29      0.38        69\n",
            "           8       0.69      0.37      0.49        91\n",
            "           9       0.93      0.82      0.87        17\n",
            "          10       0.88      0.14      0.24        50\n",
            "          11       0.43      0.64      0.51       127\n",
            "\n",
            "   micro avg       0.66      0.54      0.59      1062\n",
            "   macro avg       0.74      0.43      0.48      1062\n",
            "weighted avg       0.69      0.54      0.54      1062\n",
            " samples avg       0.58      0.47      0.50      1062\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLIno6Gyae_4",
        "outputId": "9c5acce4-719a-454a-813d-f322ba8a6186"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.7714082514022983,\n",
              " 1: 0.1459166190748144,\n",
              " 2: 0.3007355957561474,\n",
              " 3: 0.24898320650747838,\n",
              " 4: 0.7759090043784503,\n",
              " 5: 0.275228008237717,\n",
              " 6: 0.5017322064678355,\n",
              " 7: 0.279962634648156,\n",
              " 8: 0.39760046769161095,\n",
              " 9: 0.7759090043784503,\n",
              " 10: 0.22686893203883496,\n",
              " 11: 0.3849913178328437}"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFh6u9oZTM2t"
      },
      "source": [
        "**Probabilistic Classifier Chain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljSTV8tTRdr"
      },
      "source": [
        "from skml.problem_transformation import ProbabilisticClassifierChain\n",
        "pcc = ProbabilisticClassifierChain(LogisticRegression())\n",
        "pcc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jwUUmudxcQ3"
      },
      "source": [
        "# Checking on Python dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV05YG_rxbE1",
        "outputId": "d7c0e4fd-d8c1-4b6f-a43b-0239ca620845"
      },
      "source": [
        "!git clone https://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@github.com/SamridhiVaid/SAMRIDHI_RAVIKA_CMPUT663_PROJECT.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SAMRIDHI_RAVIKA_CMPUT663_PROJECT'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 57 (delta 22), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTlmpcGGFztW"
      },
      "source": [
        "    data_path = '/content/api-doc-kn-identification/SAMRIDHI_RAVIKA_CMPUT663_PROJECT/datasets/python/python_stdlib_clean.csv'\n",
        "    \n",
        "    data =  du.load_data(data_path)\n",
        "    \n",
        "    text_index = 1\n",
        "    label_start_index = 2 \n",
        "    X = [d[text_index] for d in data]\n",
        "    labels = [d[label_start_index:label_start_index+12] for d in data ]         \n",
        "    \n",
        "    Y = np.array(labels, dtype='int')\n",
        "\n",
        "    test_index = 70\n",
        "    \n",
        "       \n",
        "    tokenizer = tokenize_data(X)\n",
        "    word_index = tokenizer.word_index\n",
        "    \n",
        "    sequences = tokenizer.texts_to_sequences(X)    \n",
        "\n",
        "    X = pad_sequences(sequences, maxlen=700, \n",
        "                      padding=\"post\", truncating=\"post\", value=0)   \n",
        "\n",
        "    num_words = min(MAX_NB_WORDS, len(word_index)+1)\n",
        "    embedding_matrix = np.zeros((num_words, 1))\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        if i >= MAX_NB_WORDS:\n",
        "            continue\n",
        "        embedding_matrix[i] = 1\n",
        "        \n",
        "    X_train = X[0:test_index , :]\n",
        "    Y_train = Y[0:test_index , :]\n",
        "    x_test = X[test_index:len(X), :]\n",
        "    y_test = Y[test_index:len(Y), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toedLNXeLMVR"
      },
      "source": [
        "**Stacking Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaOea2cvGAjH",
        "outputId": "d7e4f63c-4174-4cc7-937d-0d2829ca58dc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "estimators_list = [('ExtraTrees', ExtraTreesClassifier(n_estimators=30, \n",
        "                                                       class_weight=\"balanced\", \n",
        "                                                       random_state=4621)),\n",
        "                   ('linearSVC', SVC(class_weight=\"balanced\", probability=True))]\n",
        "\n",
        "estimators_ensemble = StackingClassifier(estimators=estimators_list,\n",
        "                                         final_estimator = LogisticRegression(max_iter=300))\n",
        "\n",
        "ovr_model = OneVsRestClassifier(estimators_ensemble)\n",
        "\n",
        "ovr_model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=StackingClassifier(estimators=[('ExtraTrees',\n",
              "                                                              ExtraTreesClassifier(class_weight='balanced',\n",
              "                                                                                   n_estimators=30,\n",
              "                                                                                   random_state=4621)),\n",
              "                                                             ('linearSVC',\n",
              "                                                              SVC(class_weight='balanced',\n",
              "                                                                  probability=True))],\n",
              "                                                 final_estimator=LogisticRegression(max_iter=300)))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQARkf4GZ-N",
        "outputId": "b75cd86e-dc18-4bc6-c957-1df841516e5e"
      },
      "source": [
        "predictions = ovr_model.predict(x_test)\n",
        "   \n",
        "my_metrics= classification_report(y_test, predictions)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.83      0.31      0.45        16\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.77      0.35      0.48        94\n",
            "   macro avg       0.17      0.15      0.15        94\n",
            "weighted avg       0.39      0.35      0.35        94\n",
            " samples avg       0.80      0.38      0.48        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1WpYV54LHd0",
        "outputId": "02418e92-9489-4c7b-a549-51985b7894ba"
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "print(predictions.shape)\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], predictions[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8333333333333334,\n",
              " 1: 0.3142857142857143,\n",
              " 2: 0.6270833333333333,\n",
              " 3: 0.23333333333333334,\n",
              " 4: 0.03333333333333333,\n",
              " 5: 0.3333333333333333,\n",
              " 6: 0.13333333333333333,\n",
              " 7: 0.2,\n",
              " 8: 0.4,\n",
              " 9: 0.03333333333333333,\n",
              " 10: 0.03333333333333333,\n",
              " 11: 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3R3dCE6LnYh"
      },
      "source": [
        "**Binary Relevance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di-ZragOLqsZ",
        "outputId": "e7f3b203-b0a9-4a0e-967a-c4b64af50349"
      },
      "source": [
        "# binary relevance + RandomClassifier\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "start=time.time()\n",
        "classifier = BinaryRelevance(\n",
        "    classifier = RandomForestClassifier(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time taken:  2.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra4p6i10L2w4",
        "outputId": "3912e6c9-89e3-42d3-a250-11e07fae9bf1"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.93        25\n",
            "           1       0.18      0.33      0.24         6\n",
            "           2       0.73      0.50      0.59        16\n",
            "           3       0.20      0.14      0.17         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.20      0.17      0.18         6\n",
            "           8       0.83      0.42      0.56        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       1.00      1.00      1.00         1\n",
            "          11       1.00      0.20      0.33         5\n",
            "\n",
            "   micro avg       0.58      0.47      0.52        94\n",
            "   macro avg       0.42      0.31      0.33        94\n",
            "weighted avg       0.56      0.47      0.49        94\n",
            " samples avg       0.70      0.49      0.51        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g28GjfkaMAML",
        "outputId": "a308a94b-b4da-4b04-a196-bde0a5a16260"
      },
      "source": [
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], predictions[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8333333333333334,\n",
              " 1: 0.3142857142857143,\n",
              " 2: 0.6270833333333333,\n",
              " 3: 0.23333333333333334,\n",
              " 4: 0.03333333333333333,\n",
              " 5: 0.3333333333333333,\n",
              " 6: 0.13333333333333333,\n",
              " 7: 0.2,\n",
              " 8: 0.4,\n",
              " 9: 0.03333333333333333,\n",
              " 10: 0.03333333333333333,\n",
              " 11: 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obs1osflMNyc",
        "outputId": "f427a78c-a2bf-4593-a459-d548b85d7d1a"
      },
      "source": [
        "start=time.time()\n",
        "classifier = BinaryRelevance(\n",
        "    classifier = SVC(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time taken:  0.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WHk4vKMa_w",
        "outputId": "a76933d1-aad6-4044-b1a2-88e090e58bbc"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.29      0.67      0.40         6\n",
            "           2       0.67      0.50      0.57        16\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.66      0.39      0.49        94\n",
            "   macro avg       0.15      0.18      0.16        94\n",
            "weighted avg       0.35      0.39      0.36        94\n",
            " samples avg       0.72      0.40      0.49        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQrKvHjAMigG",
        "outputId": "2554f568-09ca-4ad1-e631-f68de6b68705"
      },
      "source": [
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], predictions[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8333333333333334,\n",
              " 1: 0.3142857142857143,\n",
              " 2: 0.6270833333333333,\n",
              " 3: 0.23333333333333334,\n",
              " 4: 0.03333333333333333,\n",
              " 5: 0.3333333333333333,\n",
              " 6: 0.13333333333333333,\n",
              " 7: 0.2,\n",
              " 8: 0.4,\n",
              " 9: 0.03333333333333333,\n",
              " 10: 0.03333333333333333,\n",
              " 11: 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9v3lguWMEIc"
      },
      "source": [
        "**Label Powerset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-MuTDLmMy9k",
        "outputId": "07454f62-02a8-4cd3-a9bb-de50d2ab0068"
      },
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "classifier = LabelPowerset(\n",
        "    classifier = SVC(),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "start=time.time()\n",
        "classifier.fit(X_train, Y_train)\n",
        "print('training time taken: ',round(time.time()-start,0),'seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time taken:  0.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebZ98PCHM9PC",
        "outputId": "b1265d34-3725-410b-c117-04456839dd9a"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        16\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.17      1.00      0.29         5\n",
            "\n",
            "   micro avg       0.50      0.32      0.39        94\n",
            "   macro avg       0.08      0.17      0.10        94\n",
            "weighted avg       0.23      0.32      0.26        94\n",
            " samples avg       0.50      0.38      0.41        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnGvg_IcNFUZ",
        "outputId": "553b03db-0730-4684-f460-d2ac1ea55f0e"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8333333333333334,\n",
              " 1: 0.2,\n",
              " 2: 0.5333333333333333,\n",
              " 3: 0.23333333333333334,\n",
              " 4: 0.03333333333333333,\n",
              " 5: 0.3333333333333333,\n",
              " 6: 0.13333333333333333,\n",
              " 7: 0.2,\n",
              " 8: 0.4,\n",
              " 9: 0.03333333333333333,\n",
              " 10: 0.03333333333333333,\n",
              " 11: 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4ZdBqm4NSCZ"
      },
      "source": [
        "**Classifier Chain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj05FUMdNYPw",
        "outputId": "9cb62e45-966a-407a-9feb-c1caeb5842a3"
      },
      "source": [
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "\n",
        "classifier = ClassifierChain(\n",
        "    classifier = RandomForestClassifier(),\n",
        "    require_dense = [False, True],\n",
        "    order=[i for i in range(12)]\n",
        ")\n",
        "start=time.time()\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassifierChain(classifier=RandomForestClassifier(),\n",
              "                order=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
              "                require_dense=[False, True])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGeeIYP7NgTd",
        "outputId": "51b0dc50-b3b2-4e62-d568-a8c5a5d40428"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.40      0.67      0.50         6\n",
            "           2       0.73      0.50      0.59        16\n",
            "           3       0.43      0.43      0.43         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.67      0.17      0.27        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       1.00      1.00      1.00         1\n",
            "          11       1.00      0.40      0.57         5\n",
            "\n",
            "   micro avg       0.59      0.48      0.53        94\n",
            "   macro avg       0.42      0.35      0.36        94\n",
            "weighted avg       0.55      0.48      0.48        94\n",
            " samples avg       0.71      0.49      0.53        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD51BcQ6NoJB",
        "outputId": "8437e9a7-ebfc-4e63-f569-97ec6338b71d"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8333333333333334,\n",
              " 1: 0.33333333333333337,\n",
              " 2: 0.6303030303030304,\n",
              " 3: 0.3170068027210884,\n",
              " 4: 0.03333333333333333,\n",
              " 5: 0.3333333333333333,\n",
              " 6: 0.13333333333333333,\n",
              " 7: 0.2,\n",
              " 8: 0.4444444444444445,\n",
              " 9: 0.03333333333333333,\n",
              " 10: 1.0,\n",
              " 11: 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkolApxVOhMW"
      },
      "source": [
        "**MLARAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1nL3sFGO0M9",
        "outputId": "4dd16ab9-b4f6-4eff-f011-68b1fdc2d637"
      },
      "source": [
        "from skmultilearn.adapt import MLARAM\n",
        "\n",
        "classifier = MLARAM(threshold=0.05, vigilance=0.95)\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLARAM(neurons=[<skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b724d0>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b72910>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b72290>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b72d10>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f753ccf2990>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f753c...\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b78c50>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b78d90>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b78990>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b2b590>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b2b450>,\n",
              "                <skmultilearn.adapt.mlaram.Neuron object at 0x7f7538b2be50>, ...],\n",
              "       threshold=0.05, vigilance=0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLfh-_s-VCkc",
        "outputId": "a1634215-959e-41d1-9d84-b5448e86f40a"
      },
      "source": [
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(my_metrics1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        16\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.83      0.27      0.40        94\n",
            "   macro avg       0.07      0.08      0.08        94\n",
            "weighted avg       0.22      0.27      0.24        94\n",
            " samples avg       0.83      0.31      0.43        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijjok08BVrSU",
        "outputId": "9bdf9e03-e738-4cb0-a3ac-0990b0fd14d3"
      },
      "source": [
        "from skmultilearn.ensemble import MajorityVotingClassifier\n",
        "from skmultilearn.cluster import FixedLabelSpaceClusterer\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classifier = MajorityVotingClassifier(\n",
        "    clusterer = FixedLabelSpaceClusterer(clusters = [[1,2,3], [0, 2, 5], [4, 5]]),\n",
        "    classifier = ClassifierChain(classifier=RandomForestClassifier())\n",
        ")\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MajorityVotingClassifier(classifier=ClassifierChain(classifier=RandomForestClassifier(),\n",
              "                                                    require_dense=[True, True]),\n",
              "                         clusterer=FixedLabelSpaceClusterer(clusters=[[1, 2, 3],\n",
              "                                                                      [0, 2, 5],\n",
              "                                                                      [4, 5]]),\n",
              "                         require_dense=[False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-45UVoFV4XJ",
        "outputId": "ee83902a-bd1e-4b2b-d0e6-69c9b9517f96"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predictions1 = classifier.predict(x_test)\n",
        "   \n",
        "#my_metrics1= classification_report(y_test, predictions1)\n",
        "\n",
        "#print(scores)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        25\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.83      0.31      0.45        16\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        12\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.77      0.35      0.48        94\n",
            "   macro avg       0.17      0.15      0.15        94\n",
            "weighted avg       0.39      0.35      0.35        94\n",
            " samples avg       0.80      0.38      0.48        94\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adx0WPh0VuNA"
      },
      "source": [
        "pred = predictions1.toarray()\n",
        "average_precision = dict()\n",
        "for i in range(12):\n",
        "    average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])\n",
        "\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}