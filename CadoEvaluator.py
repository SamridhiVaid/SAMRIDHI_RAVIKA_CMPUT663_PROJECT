# -*- coding: utf-8 -*-
"""SA_Project_stacking classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DnqIcbdhG32qSTUNlaCKsw38R-IBVyNK
"""



# Commented out IPython magic to ensure Python compatibility.
# %cd SAMRIDHI_RAVIKA_CMPUT663_PROJECT

"""# Ensemble Learning on Cado Dataset"""

import scripts.dataset_utils as du

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

import numpy as np
from sklearn.metrics import classification_report, hamming_loss, accuracy_score
from sklearn.metrics import average_precision_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.ensemble import StackingClassifier
from sklearn.multiclass import OneVsRestClassifier
from skmultilearn.problem_transform import BinaryRelevance, LabelPowerset, ClassifierChain
from sklearn.ensemble import RandomForestClassifier
import time
import os
import sys

MAX_NB_WORDS =20000

def tokenize_data(X):
    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)
    tokenizer.fit_on_texts(X)       
    return tokenizer

def preprocess_cado_data():

    print("Preprocessing data")
    data_path = 'datasets/cado/test.csv'
    test_path = 'datasets/cado/test.csv'
    
    data =  du.load_data(data_path)
    test = du.load_data(test_path)
    
    text_index = 6
    label_start_index = 7 
    X = [d[text_index] for d in data]
    labels = [d[label_start_index:label_start_index+12] for d in data ]
    
    
    X_test = [d[text_index] for d in test]
    labels_test = [d[label_start_index:label_start_index+12] for d in test]
    
        
    
    Y = np.array(labels, dtype='int')
    y_test = np.array(labels_test, dtype='int')
    #Y = np.array(binary_labels, dtype='int')
    
    test_index = len(X)
    
    X = X + X_test
    Y = np.vstack([Y , y_test])
    
    tokenizer = tokenize_data(X)
    word_index = tokenizer.word_index
    
    sequences = tokenizer.texts_to_sequences(X)    

    X = pad_sequences(sequences, maxlen=700, 
                      padding="post", truncating="post", value=0)   

    num_words = min(MAX_NB_WORDS, len(word_index)+1)
    embedding_matrix = np.zeros((num_words, 1))

    for word, i in word_index.items():
        if i >= MAX_NB_WORDS:
            continue
        embedding_matrix[i] = 1
        
    X_train = X[0:test_index , :]
    Y_train = Y[0:test_index , :]
    x_test = X[test_index:len(X), :]
    y_test = Y[test_index:len(Y), :]
    print("Preprocessing complete.")
    return X_train, Y_train, x_test, y_test



"""**Stacking Classifier**"""

# Stacking classifier with one vs Rest wrapper and MLKnn - Model 1
def run_stacking_classifier():
    print("Running model...")
    estimators_list = [('ExtraTrees', ExtraTreesClassifier(n_estimators=30,
                                                       class_weight="balanced", 
                                                       random_state=4621)),
                   ('linearSVC', SVC(class_weight="balanced", probability=True))]
    estimators_ensemble = StackingClassifier(estimators=estimators_list,
                                         final_estimator = LogisticRegression(max_iter=300))
    ovr_model = OneVsRestClassifier(estimators_ensemble)
    ovr_model.fit(X_train, Y_train)
    predictions = ovr_model.predict(x_test)
    my_metrics= classification_report(y_test, predictions)
    print(my_metrics)
    print ("Hamming Loss:" )
    print(hamming_loss(y_test,predictions))
    print("Accuracy Score: ")
    print(accuracy_score(y_test,predictions))

    average_precision = dict()
    for i in range(12):
        average_precision[i] = average_precision_score(y_test[:, i], predictions[:, i])

    print("Average Precision:")
    print(average_precision)

"""**BinaryRelevance**"""

# binary relevance + RandomClassifier

def run_binary_relevance():
    print("Running model...")
    start=time.time()
    classifier = BinaryRelevance(classifier = RandomForestClassifier(),require_dense = [False, True])
    classifier.fit(X_train, Y_train)
    print('training time taken: ',round(time.time()-start,0),'seconds')
    predictions1 = classifier.predict(x_test)
    my_metrics1= classification_report(y_test, predictions1)
    print(my_metrics1)
    print ("Hamming Loss:" )
    print(hamming_loss(y_test,predictions1))
    print("Accuracy Score: ")
    print(accuracy_score(y_test,predictions1))
    pred = predictions1.toarray()
    average_precision = dict()
    for i in range(12):
        average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])
    print("Average Precision:")
    print(average_precision)



"""**Label Powerset**"""

def run_label_powerset():
    print("Running model...")
    classifier = LabelPowerset( classifier = SVC(), require_dense = [False, True])
    start=time.time()
    classifier.fit(X_train, Y_train)
    print('training time taken: ',round(time.time()-start,0),'seconds')
    predictions1 = classifier.predict(x_test)
    my_metrics1= classification_report(y_test, predictions1)
    print(my_metrics1)
    print ("Hamming Loss:" )
    print(hamming_loss(y_test,predictions1))
    print("Accuracy Score: ")
    print(accuracy_score(y_test,predictions1))
    pred = predictions1.toarray()
    average_precision = dict()
    for i in range(12):
        average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])
    print("Average Precision:")
    print(average_precision)

"""

**ClassifierChain**
"""

def run_classifier_chain():
    print("Running model...")
    classifier = ClassifierChain(classifier = RandomForestClassifier(),require_dense = [False, True],
                                 order=[i for i in range(12)])
    start=time.time()
    classifier.fit(X_train,Y_train)
    predictions1 = classifier.predict(x_test)
    my_metrics1= classification_report(y_test, predictions1)
    print(my_metrics1)
    print("Hamming Loss:")
    print(hamming_loss(y_test, predictions1))
    print("Accuracy Score: ")
    print(accuracy_score(y_test, predictions1))
    pred = predictions1.toarray()
    average_precision = dict()
    for i in range(12):
        average_precision[i] = average_precision_score(y_test[:, i], pred[:, i])
    print("Average Precision:")
    print(average_precision)


## main method##


if (len(sys.argv) < 2 ):
    print("No optional argument passed. Pass an optional argument to choose a model to run. ")
    exit()
else:
    model_arg = sys.argv[1]

# calling different methods with optional arguments
X_train, Y_train, x_test, y_test = preprocess_cado_data()
if model_arg == "--stacking":
    run_stacking_classifier()
elif model_arg == "--binaryrelevance":
    run_binary_relevance()
elif model_arg == "--labelpowerset":
    run_label_powerset()
elif model_arg == "--classifierchain":
    run_classifier_chain()
