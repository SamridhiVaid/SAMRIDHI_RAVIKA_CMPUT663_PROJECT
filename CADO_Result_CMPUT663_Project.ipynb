{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"CADO_Result_CMPUT663_Project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVtxXUapLBsA","executionInfo":{"status":"ok","timestamp":1638170342709,"user_tz":420,"elapsed":206,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"26d58185-122d-417d-dfd8-84c7cd4f6458"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEoTr44dTfOw","executionInfo":{"status":"ok","timestamp":1638166055368,"user_tz":420,"elapsed":216,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"361ff399-b54c-431b-9a03-1b020c213d51"},"source":["!pwd"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jVmgQkRTmgp","executionInfo":{"status":"ok","timestamp":1638166202037,"user_tz":420,"elapsed":205,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"aed78d15-e6e4-4a0a-eafc-7db3fc5d3f62"},"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets\")\n","print(sys.path)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification', '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/scripts', '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5wuLIgRLdAP","executionInfo":{"status":"ok","timestamp":1638170383932,"user_tz":420,"elapsed":205,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"5dbbdd6d-019c-419a-fda0-751a873b0b4d"},"source":["%cd /content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJH5n_JtMJYX","executionInfo":{"elapsed":4405,"status":"ok","timestamp":1635739112508,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"},"user_tz":360},"outputId":"7df5aa15-0066-41ce-af2c-6098a4276327"},"source":["!pip install scikit-multilearn"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 3.6 MB/s \n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"6nmdPj4siA8K"},"source":["Multilabel Classifier KNN\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBWfqestkVz8","executionInfo":{"elapsed":29401,"status":"ok","timestamp":1635739479867,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"},"user_tz":360},"outputId":"60550d04-39ed-428e-e8df-e8fad94d5b57"},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","#samridhi\n","\n","import scripts.dataset_utils as du\n","from skmultilearn.adapt import MLkNN\n","import numpy as np\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.datasets import make_blobs\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay, classification_report\n"," \n","MAX_NB_WORDS =20000\n","\n","def tokenize_data(X):\n","    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","    tokenizer.fit_on_texts(X)       \n","    return tokenizer\n","\n","def get_cado_predictions():\n","    data_path = '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/train.csv'\n","    test_path = '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/test.csv'\n","    \n","    data = du.load_data(data_path)\n","    test = du.load_data(test_path)\n","    \n","    text_index = 6\n","    label_start_index = 7 \n","    X = [d[text_index] for d in data]\n","    labels = [d[label_start_index:label_start_index+12] for d in data ]\n","    \n","    \n","    X_test = [d[text_index] for d in test]\n","    labels_test = [d[label_start_index:label_start_index+12] for d in test]\n","    \n","        \n","    \n","    Y = np.array(labels, dtype='int')\n","    y_test = np.array(labels_test, dtype='int')\n","    #Y = np.array(binary_labels, dtype='int')\n","    \n","    test_index = len(X)\n","    \n","    X = X + X_test\n","    Y = np.vstack([Y , y_test])\n","    \n","    tokenizer = tokenize_data(X)\n","    word_index = tokenizer.word_index\n","    \n","    sequences = tokenizer.texts_to_sequences(X)    \n","\n","    X = pad_sequences(sequences, maxlen=700, \n","                      padding=\"post\", truncating=\"post\", value=0)   \n","\n","    num_words = min(MAX_NB_WORDS, len(word_index)+1)\n","    embedding_matrix = np.zeros((num_words, 1))\n","\n","    for word, i in word_index.items():\n","        if i >= MAX_NB_WORDS:\n","            continue\n","        embedding_matrix[i] = 1\n","        \n","    X_train = X[0:test_index , :]\n","    Y_train = Y[0:test_index , :]\n","    x_test = X[test_index:len(X), :]\n","    y_test = Y[test_index:len(Y), :]\n","    \n","    classifier = MLkNN()\n","    classifier.fit(X_train,Y_train)\n","    predictions = classifier.predict(x_test)\n","    scores = classifier.predict_proba(x_test)\n","    y_pred= predictions.toarray()\n","    y_score= scores.toarray()\n","    \n","    \n","    \n","    print(classification_report(y_test, y_pred))\n","   \n","    return y_pred, y_score\n","    \n","if __name__ == \"__main__\":\n","    \n","    p, pr = get_cado_predictions()\n","    \n","    \n","\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.96      0.84       302\n","           1       0.46      0.12      0.19        51\n","           2       0.44      0.11      0.18        71\n","           3       0.50      0.05      0.10        74\n","           4       0.43      0.18      0.25        17\n","           5       0.17      0.06      0.09        33\n","           6       0.43      0.39      0.41       160\n","           7       0.43      0.33      0.38        69\n","           8       0.45      0.30      0.36        91\n","           9       0.33      0.06      0.10        17\n","          10       0.17      0.02      0.04        50\n","          11       0.37      0.28      0.32       127\n","\n","   micro avg       0.57      0.44      0.50      1062\n","   macro avg       0.41      0.24      0.27      1062\n","weighted avg       0.50      0.44      0.43      1062\n"," samples avg       0.59      0.39      0.44      1062\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"cI0O1_igpg23"},"source":["Multilabel Classifier LSTM CCOTF\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cvFBW86os9g","executionInfo":{"status":"ok","timestamp":1638155528670,"user_tz":420,"elapsed":19840055,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"1f3c7075-df83-46ca-b117-9000d503342e"},"source":["!python scripts/multi_label_classifier_lstm.py \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/glove.840B.300d.txt\" 300 \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/train.csv\" \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/test.csv\" \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/results\" True\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["4136 documents.\n","131455005 tokens.\n","16215 unique tokens.\n","115 average tokens per document.\n","2874 max tokens per document.\n","3 min tokens per document.\n","Shape of data tensor: (4136, 800)\n","Shape of label tensor: (4136, 12)\n","Preparing embedding matrix.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","Found 2195884 word vectors.\n","Preparing taraining and validation matrix.\n","Build model...\n","2021-11-28 21:44:57.956820: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-11-28 21:44:58.087518: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19459200 exceeds 10% of free system memory.\n","2021-11-28 21:44:58.204753: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19459200 exceeds 10% of free system memory.\n","2021-11-28 21:44:58.225620: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19459200 exceeds 10% of free system memory.\n","Train...\n","Epoch 1/100\n","2021-11-28 21:44:59.910788: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19459200 exceeds 10% of free system memory.\n","2021-11-28 21:44:59.930518: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19459200 exceeds 10% of free system memory.\n","105/105 [==============================] - 901s 9s/step - loss: 0.4528 - accuracy: 0.7747 - f1: 0.4421 - val_loss: 0.4254 - val_accuracy: 0.8257 - val_f1: 0.4522\n","Epoch 2/100\n","105/105 [==============================] - 895s 9s/step - loss: 0.4126 - accuracy: 0.7368 - f1: 0.4936 - val_loss: 0.3999 - val_accuracy: 0.8150 - val_f1: 0.5338\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 909s 9s/step - loss: 0.4384 - accuracy: 0.7869 - f1: 0.4597 - val_loss: 0.4215 - val_accuracy: 0.7828 - val_f1: 0.4768\n","Epoch 2/100\n","105/105 [==============================] - 949s 9s/step - loss: 0.3941 - accuracy: 0.7648 - f1: 0.5324 - val_loss: 0.3883 - val_accuracy: 0.7507 - val_f1: 0.5348\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 956s 9s/step - loss: 0.4399 - accuracy: 0.7845 - f1: 0.4551 - val_loss: 0.4080 - val_accuracy: 0.8231 - val_f1: 0.5325\n","Epoch 2/100\n","105/105 [==============================] - 959s 9s/step - loss: 0.4128 - accuracy: 0.7777 - f1: 0.4991 - val_loss: 0.3905 - val_accuracy: 0.8177 - val_f1: 0.5234\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 968s 9s/step - loss: 0.4369 - accuracy: 0.7839 - f1: 0.4617 - val_loss: 0.3965 - val_accuracy: 0.7962 - val_f1: 0.5240\n","Epoch 2/100\n","105/105 [==============================] - 978s 9s/step - loss: 0.3921 - accuracy: 0.7514 - f1: 0.5304 - val_loss: 0.3718 - val_accuracy: 0.7828 - val_f1: 0.5677\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 964s 9s/step - loss: 0.4363 - accuracy: 0.7058 - f1: 0.4840 - val_loss: 0.4035 - val_accuracy: 0.6371 - val_f1: 0.5544\n","Epoch 2/100\n","105/105 [==============================] - 975s 9s/step - loss: 0.3762 - accuracy: 0.7524 - f1: 0.5536 - val_loss: 0.3886 - val_accuracy: 0.6640 - val_f1: 0.5632\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 968s 9s/step - loss: 0.4188 - accuracy: 0.7020 - f1: 0.4814 - val_loss: 0.3670 - val_accuracy: 0.8091 - val_f1: 0.5861\n","Epoch 2/100\n","105/105 [==============================] - 1005s 10s/step - loss: 0.3677 - accuracy: 0.6715 - f1: 0.5697 - val_loss: 0.3565 - val_accuracy: 0.7930 - val_f1: 0.6087\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 987s 9s/step - loss: 0.4237 - accuracy: 0.7440 - f1: 0.4862 - val_loss: 0.3773 - val_accuracy: 0.7688 - val_f1: 0.5167\n","Epoch 2/100\n","105/105 [==============================] - 998s 10s/step - loss: 0.3577 - accuracy: 0.6844 - f1: 0.5882 - val_loss: 0.3598 - val_accuracy: 0.5054 - val_f1: 0.5703\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 984s 9s/step - loss: 0.4134 - accuracy: 0.7220 - f1: 0.5102 - val_loss: 0.3451 - val_accuracy: 0.6559 - val_f1: 0.5562\n","Epoch 2/100\n","105/105 [==============================] - 1000s 10s/step - loss: 0.3561 - accuracy: 0.6662 - f1: 0.5996 - val_loss: 0.3232 - val_accuracy: 0.4516 - val_f1: 0.6081\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 955s 9s/step - loss: 0.4080 - accuracy: 0.6981 - f1: nan - val_loss: 0.3456 - val_accuracy: 0.5672 - val_f1: 0.6086\n","Epoch 2/100\n","105/105 [==============================] - 950s 9s/step - loss: 0.3462 - accuracy: 0.6274 - f1: 0.6147 - val_loss: 0.3282 - val_accuracy: 0.5780 - val_f1: 0.6299\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 1007s 10s/step - loss: 0.4029 - accuracy: 0.7318 - f1: 0.5164 - val_loss: 0.3619 - val_accuracy: 0.7500 - val_f1: 0.5662\n","Epoch 2/100\n","105/105 [==============================] - 971s 9s/step - loss: 0.3361 - accuracy: 0.6092 - f1: 0.6279 - val_loss: 0.3291 - val_accuracy: 0.6183 - val_f1: 0.6090\n"]}]},{"cell_type":"code","metadata":{"id":"B1egvK1TzPmi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638170453628,"user_tz":420,"elapsed":44840,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"c186cbf5-6b60-4f43-c696-917a5395b09d"},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.models import model_from_json\n","import numpy\n","import os\n","import scripts.dataset_utils as du\n","import numpy as np\n","import scripts.lstm_configs as lstm_configs\n","\n","from scripts.multi_label_classifier_lstm import precision, recall, f1\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import os\n","import sys\n","def precision(y_true, y_pred):\n","    \"\"\"Precision metric.\n","\n","    Only computes a batch-wise average of precision.\n","\n","    Computes the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    \"\"\"\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","    \n","MAX_NB_WORDS =20000\n","\n","def tokenize_data(X):\n","    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","    tokenizer.fit_on_texts(X)       \n","    return tokenizer\n","data_path = '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/train.csv'\n","test_path = '/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/test.csv'\n","    \n","data = du.load_data(data_path)\n","test = du.load_data(test_path)\n","    \n","text_index = 6\n","label_start_index = 7 \n","X = [d[text_index] for d in data]\n","labels = [d[label_start_index:label_start_index+12] for d in data ]\n","    \n","    \n","X_test = [d[text_index] for d in test]\n","labels_test = [d[label_start_index:label_start_index+12] for d in test]\n","    \n","        \n","    \n","Y = np.array(labels, dtype='int')\n","y_test = np.array(labels_test, dtype='int')\n","#Y = np.array(binary_labels, dtype='int')\n","    \n","test_index = len(X)\n","    \n","X = X + X_test\n","Y = np.vstack([Y , y_test])\n","    \n","tokenizer = tokenize_data(X)\n","word_index = tokenizer.word_index\n","    \n","sequences = tokenizer.texts_to_sequences(X)    \n","X = pad_sequences(sequences, maxlen=lstm_configs.MAX_SEQUENCE_LENGTH, \n","                      padding=\"post\", truncating=\"post\", value=0)   \n","\n","num_words = min(MAX_NB_WORDS, len(word_index)+1)\n","embedding_matrix = np.zeros((num_words, 1))\n","\n","for word, i in word_index.items():\n","  if i >= MAX_NB_WORDS:\n","    continue\n","    embedding_matrix[i] = 1\n","        \n","X_train = X[0:test_index , :]\n","Y_train = Y[0:test_index , :]\n","x_test = X[test_index:len(X), :]\n","y_test = Y[test_index:len(Y), :]\n","# load json and create model\n","json_file = open('model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"lstm_model.h5\")\n","print(\"Loaded model from disk\")\n"," \n","loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","score = loaded_model.evaluate(x_test, y_test)\n","print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n","prediction=loaded_model.predict(x_test)\n","\n"],"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded model from disk\n","13/13 [==============================] - 16s 1s/step - loss: 0.3715 - accuracy: 0.6942\n","accuracy: 69.42%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gl0KQZ6wVRev","executionInfo":{"status":"ok","timestamp":1638170501147,"user_tz":420,"elapsed":193,"user":{"displayName":"Samridhi Vaid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAwEP1GE2OgvoIJJINuIgVLHRVIgIL0c0zfVl3=s64","userId":"14409023206372227637"}},"outputId":"19f0fc0a-f13b-465e-a353-c5fdd780fd7f"},"source":["y_test2=y_test.copy()\n","y_test2=y_test2.astype(float)\n","\n","\n","prediction2=prediction.copy()\n","prediction2=prediction2.astype(float)\n","\n","print(\"Precision:\", precision(y_test2, prediction2))\n","print(\"Recall:\", recall(y_test2, prediction2))\n","print(\"f1:\", f1(y_test2, prediction2))"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: tf.Tensor(0.7019774010307942, shape=(), dtype=float64)\n","Recall: tf.Tensor(0.4679849340425626, shape=(), dtype=float64)\n","f1: tf.Tensor(0.5615819208404992, shape=(), dtype=float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"MvLmLGcIjZzN"},"source":["Multilabel Classifier LSTM CC"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_aaLitevsIa","outputId":"ba20e524-9fb6-4e22-ddc0-3f89b2b09a26"},"source":["!python scripts/multi_label_classifier_lstm.py \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/glove.840B.300d.txt\" 300 \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/train.csv\" \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/test.csv\" \"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/results\" False\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4136 documents.\n","131455005 tokens.\n","16215 unique tokens.\n","115 average tokens per document.\n","2874 max tokens per document.\n","3 min tokens per document.\n","Shape of data tensor: (4136, 800)\n","Shape of label tensor: (4136, 12)\n","Preparing embedding matrix.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","emb val err.\n","Found 2195884 word vectors.\n","Preparing taraining and validation matrix.\n","Build model...\n","2021-11-29 07:25:20.235184: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Train...\n","Epoch 1/100\n","2021-11-29 07:25:24.596310: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.\n","2021-11-29 07:25:24.611769: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.\n","2021-11-29 07:25:27.837716: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n","2021-11-29 07:25:27.897168: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n","2021-11-29 07:25:34.588853: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.\n","105/105 [==============================] - 957s 9s/step - loss: 0.4551 - accuracy: 0.7550 - f1: 0.4300 - val_loss: 0.4241 - val_accuracy: 0.8257 - val_f1: 0.4478\n","Epoch 2/100\n","105/105 [==============================] - 946s 9s/step - loss: 0.4041 - accuracy: 0.7702 - f1: 0.4971 - val_loss: 0.3970 - val_accuracy: 0.7185 - val_f1: 0.5257\n","Build model...\n","Train...\n","Epoch 1/100\n","105/105 [==============================] - 986s 9s/step - loss: 0.4568 - accuracy: 0.7359 - f1: nan - val_loss: 0.4437 - val_accuracy: 0.7828 - val_f1: 0.4203\n","Epoch 2/100\n","105/105 [==============================] - 984s 9s/step - loss: 0.4199 - accuracy: 0.8016 - f1: 0.4739 - val_loss: 0.4098 - val_accuracy: 0.7802 - val_f1: 0.4714\n","Build model...\n","Train...\n","Epoch 1/100\n"," 54/105 [==============>...............] - ETA: 7:55 - loss: 0.4588 - accuracy: 0.7130 - f1: 0.4216"]}]},{"cell_type":"markdown","metadata":{"id":"paOuJoZTj1Hb"},"source":["Multi Label SVM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZYUps_YGTmO","executionInfo":{"elapsed":643,"status":"ok","timestamp":1635409182886,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"d8977452-0212-4ae7-c21c-8dc6456d38bb"},"source":["import csv\n","import string\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.model_selection import cross_val_score\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.externals import joblib\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","\n","import nltk\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MEmTi6NGVeA","executionInfo":{"elapsed":152,"status":"ok","timestamp":1635409188948,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"ea6f06d6-55fe-4300-f086-bd66d914330c"},"source":["print(\"Loading data\")\n","test_df = pd.read_csv(\"/content/api-doc-kn-identification/datasets/cado/test.csv\", skiprows=1)\n","test_df = test_df[test_df.columns.drop(list(test_df.filter(regex='Unnamed*')))]\n","test_df = test_df[pd.notnull(test_df['text'])]\n","print(test_df.shape)\n","print(test_df.columns)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data\n","(412, 21)\n","Index(['id', 'quoteId', 'elementId', 'projectId', 'elementName', 'text',\n","       'functionality', 'concept', 'directives', 'purpose', 'quality',\n","       'control', 'structure', 'patterns', 'codeExamples', 'environment',\n","       'reference', 'nonInformation', 'knCount', 'length', 'Three class'],\n","      dtype='object')\n"]}]},{"cell_type":"code","metadata":{"id":"K7T7jEdhHHGx"},"source":["np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6-gE5E9HNYK"},"source":["import pandas as pd\n","train_df = pd.read_csv(\"/content/drive/MyDrive/CMPUT663_2/api-doc-kn-identification/datasets/cado/test2.csv\", skiprows=1)\n","train_df = train_df[train_df.columns.drop(list(train_df.filter(regex='Unnamed*')))]\n","train_df = train_df[pd.notnull(train_df['text'])]\n","\n","\n","train_df.to_csv('test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6E26ACDHtYV"},"source":["def load_data(data_path, header=True):\n","    data = open(data_path, 'r')\n","    data_reader = csv.reader(data, delimiter=',')\n","    if header:\n","        next(data_reader, None)  # skip the headers\n","\n","    data = list(data_reader)\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TEJMtv9HwbO"},"source":["def undersample_dataset(dataset, dims, n_samples):\n","    for dim in dims:\n","        col = np.array([d[dim] for d in dataset], dtype=\"int32\")\n","        col_indexes = np.nonzero(col)\n","        random_indexes = np.random.choice(\n","            [x for xs in col_indexes for x in xs], n_samples, replace=False)\n","\n","        elements = [dataset[x] for x in random_indexes]\n","        col_indexes = np.where(col < 1)\n","        col_indexes = [x for xs in col_indexes for x in xs]\n","        dataset_tmp = [dataset[x] for x in col_indexes]\n","\n","        dataset = elements + dataset_tmp\n","\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1oXG9svHziX"},"source":["def oversample_dataset(dataset, dims, n_samples):\n","\n","    for dim in dims:\n","        col = np.array([d[dim] for d in dataset], dtype=\"int\")\n","        col_indexes = [x for xs in np.nonzero(col) for x in xs]\n","        random_indexes = np.random.choice(col_indexes, n_samples, replace=True)\n","\n","        elements = [dataset[x] for x in random_indexes]\n","        col_indexes = np.where(col < 1)\n","        col_indexes = [x for xs in col_indexes for x in xs]\n","        dataset_tmp = [dataset[x] for x in col_indexes]\n","\n","        dataset = elements + dataset_tmp\n","\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0e4ysPE4H9TZ"},"source":["def create_bow_df(data, text_column):\n","    bow_transformer_uni = CountVectorizer(\n","        strip_accents='unicode', stop_words='english', ngram_range=(1, 1), max_features=800)\n","\n","    bow_transformer_bi = CountVectorizer(\n","        strip_accents='unicode', stop_words='english', ngram_range=(1, 2), max_features=800)\n","\n","    bow_transformer_uni.fit(data[text_column])\n","    bow_transformer_bi.fit(data[text_column])\n","\n","    text_bow_uni = bow_transformer_uni.transform(data[text_column])\n","    text_bow_bi = bow_transformer_bi.transform(data[text_column])\n","\n","    text_bow_uni_df = pd.DataFrame(text_bow_uni.toarray())\n","    text_bow_bi_df = pd.DataFrame(text_bow_bi.toarray())\n","\n","    text_bow_df = pd.concat([text_bow_bi_df, text_bow_uni_df], axis=1)\n","    text_bow_df.columns = ['bow_' + str(col) for col in text_bow_df.columns]\n","\n","    df = pd.concat([data, text_bow_df], axis=1)\n","    return df.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9g853k4IB2p","executionInfo":{"elapsed":3166,"status":"ok","timestamp":1635409221198,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"14fbe7ae-cc35-4a0e-ba4e-cd304a533eb5"},"source":["print(\"creating bow\")\n","df_train = create_bow_df(train_df, 'text')\n","df_test = create_bow_df(test_df, 'text')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["creating bow\n"]}]},{"cell_type":"code","metadata":{"id":"vHGsaGRFJiP3"},"source":["clf = SVC()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubw8exLIJmcM"},"source":["labels = ['functionality', 'concept', 'directives', 'purpose', 'quality', 'control',\n","    'structure', 'patterns', 'codeExamples', 'environment', 'reference', 'nonInformation']\n","y_test = df_test[labels]\n","y_train = df_train[labels]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NeBwoas8Jpk2"},"source":["\n","X_test = df_test.drop(labels, axis=1).filter(regex=(\"bow_*\"))\n","X_train = df_train.drop(labels, axis=1).filter(regex=(\"bow_*\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yQpiZqyJuR1"},"source":["\n"," scoring = ['precision_macro', 'recall_macro', 'f1_macro',\n","   'roc_auc', 'hamming_loss', 'accuracy_score']\n","# estimator__ necessary to get the SVC inside the OneVsRestClassifier\n","#tuned_parameters = [{'estimator__kernel': ['rbf'], 'estimator__gamma': ['auto'],\n","                     'estimator__C': [0.01]}]\n","\n","tuned_parameters = [{'estimator__kernel': ['rbf'], 'estimator__gamma': ['auto'],\n","                    'estimator__C': [0.01, 0.5, 1.0]},\n","                   {'estimator__gamma': ['auto'], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.5, 1.0]}]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaABrciqJxjC"},"source":["clf = SVC(class_weight=\"balanced\", probability=True)\n","clf = OneVsRestClassifier(clf)\n","clf = GridSearchCV(clf, tuned_parameters, cv=10, verbose=100, n_jobs=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOK7oMlpJ1Ak"},"source":["def to_label(row):\n","    a = (list(map(int, row.values)))  # apparently Series.value returns str\n","    b = np.nonzero(a)\n","    arr = y_train.columns.values[b]\n","    return arr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoeTd_DjJ4RG","executionInfo":{"elapsed":197,"status":"ok","timestamp":1635409234047,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"506e8f60-090b-420c-f2d3-7456fc240d44"},"source":["print('Creating labels')\n","y_train_labels = y_train.apply(to_label, axis=1)\n","y_test_labels = y_test.apply(to_label, axis=1)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Creating labels\n"]}]},{"cell_type":"code","metadata":{"id":"Na35yeQYJ7qK"},"source":["mlb = MultiLabelBinarizer()\n","y_train_enc = mlb.fit_transform(y_train_labels)\n","y_test_enc = mlb.fit_transform(y_test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLpyHgXd7oMk","executionInfo":{"elapsed":145,"status":"ok","timestamp":1635409237016,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"9c91ef25-eb05-4bce-9f56-65e91ecef463"},"source":["import multiprocessing\n","n_cpus = multiprocessing.cpu_count()\n","print(n_cpus)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLPzQGBRJ_il","outputId":"60b87719-50bb-4393-98a2-d64ca27e4ab1"},"source":["print('Training classifiers')\n","clf.fit(X_train, y_train_enc)\n","\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Training classifiers\n","Fitting 10 folds for each of 1 candidates, totalling 10 fits\n","[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V26LrY3M6AP2","executionInfo":{"elapsed":1580,"status":"ok","timestamp":1635408539443,"user":{"displayName":"Ravika Nagpal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16628421063162706797"},"user_tz":360},"outputId":"6fea3bd6-79d9-404d-ccfb-97f0ec510369"},"source":["print('Saving to file')\n","joblib.dump(clf, 'svm.pkl')\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Saving to file\n"]},{"data":{"text/plain":["['svm.pkl']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"70qu_84y2LYS"},"source":["print('Calculating score')\n","\n","for score in scoring:\n","    print(score),\n","    print(\":\"),\n","    print(cross_val_score(clf, X_test, y_test_enc, cv=10, n_jobs=4, verbose=100, scoring=score))\n","\n","predictions = cross_val_predict(clf, X_test, y_test_enc, cv=10, n_jobs=4, verbose=10)\n","my_metrics= metrics.classification_report(y_test_enc, predictions)\n","\n","#print(scores)\n","print(my_metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dn4XSMDq98s0"},"source":["precision    recall  f1-score   support\n","\n","           0       0.23      0.22      0.23        85\n","           1       0.10      0.14      0.11        50\n","           2       0.03      0.03      0.03        32\n","           3       0.15      0.17      0.16        65\n","           4       0.00      0.00      0.00        15\n","           5       0.83      0.82      0.82       290\n","           6       0.32      0.46      0.38       123\n","           7       0.19      0.17      0.18        64\n","           8       0.19      0.14      0.16        71\n","           9       0.00      0.00      0.00        16\n","          10       0.09      0.15      0.11        48\n","          11       0.41      0.49      0.45       154\n","\n","   micro avg       0.38      0.43      0.40      1013\n","   macro avg       0.21      0.23      0.22      1013\n","weighted avg       0.40      0.43      0.41      1013\n"," samples avg       0.40      0.45      0.39      1013\n"]}]}